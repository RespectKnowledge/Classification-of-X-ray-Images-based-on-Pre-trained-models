{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification of X-ray Images based on pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can download dataset from this link\n",
    "# https://drive.google.com/drive/folders/1Uz864NKSDTtLsGI48ijzkz4vjW_Uad5W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil\n",
    "os.environ['QT_QPA_PLATFORM']='offscreen'\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import glob\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits import mplot3d\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten, Reshape, Activation,SimpleRNN,GRU, LSTM\n",
    "from keras.layers.convolutional import Conv2D,Conv3D, Conv2DTranspose, Conv3DTranspose\n",
    "from keras.layers.convolutional import MaxPooling2D,MaxPooling3D, UpSampling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, GRU, Dropout, Activation, Bidirectional, Conv2D, MaxPooling2D\n",
    "from keras import optimizers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "#%Read the train & test Images and preprocessing\n",
    "train_images = []\n",
    "train_labels = [] \n",
    "for directory_path in glob.glob(\"/raid/Home/Users/aqayyum/pymultimodel/Classificationmodels/Datasetnew/*\"):\n",
    "    label = directory_path.split(\"\\\\\")[-1]\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "        img = cv2.resize(img, (139, 139))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        train_images.append(img)\n",
    "        train_labels.append(label)\n",
    "train_images = np.array(train_images)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "label_to_id = {v:i for i,v in enumerate(np.unique(train_labels))}\n",
    "id_to_label = {v: k for k, v in label_to_id.items()}\n",
    "train_label_ids = np.array([label_to_id[x] for x in train_labels])\n",
    "#image_data = image_data.reshape(-1,10,24,24,1)\n",
    "train_images.shape, train_label_ids.shape, train_labels.shape\n",
    "\n",
    "\n",
    "X_train1, y_train1, N_CATEGORY =train_images,train_label_ids,len(label_to_id)\n",
    "\n",
    "print(X_train1.shape, y_train1.shape, N_CATEGORY)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train1, y_train1, test_size=0.2)\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "from keras import utils as np_utils\n",
    "#Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = keras.utils.to_categorical(Y_train, 3)\n",
    "y_test = keras.utils.to_categorical(Y_test, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import keras\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.applications.xception import Xception\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import os\n",
    "#%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras.applications import *\n",
    "from sklearn.manifold import TSNE\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras_applications.resnet import ResNet50\n",
    "from keras_applications import resnext\n",
    "from keras_applications import resnet_v2\n",
    "from keras_applications import resnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I developed the function using most of the pre-trained models\n",
    "def cnn_load_model(model='inceptionv3'):\n",
    "    im_size=224\n",
    "    if model == 'xception':\n",
    "        cnn_model = Xception(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet')\n",
    "    if model == 'ResNet50':\n",
    "        cnn_model = keras.applications.ResNet50(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet')\n",
    "    if model == 'ResNet101':\n",
    "        cnn_model=resnet.ResNet101(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet',\n",
    "                                    backend = keras.backend, layers = keras.layers, models = keras.models, utils = keras.utils)\n",
    "    if model == 'ResNet152':\n",
    "        cnn_model=resnet.ResNet152(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet',\n",
    "                                    backend = keras.backend, layers = keras.layers, models = keras.models, utils = keras.utils)\n",
    "    if model == 'ResNet50V2':\n",
    "        cnn_model=resnet_v2.ResNet50V2(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet',\n",
    "                                                  backend = keras.backend, layers = keras.layers, models = keras.models, utils = keras.utils)\n",
    "    if model == 'ResNeXt50':\n",
    "        cnn_model=resnext.ResNeXt50(\n",
    "        input_shape=(im_size, im_size, 3), include_top = False, weights = 'imagenet', \n",
    "        backend = keras.backend, layers = keras.layers, models = keras.models, utils = keras.utils)\n",
    "    if model == 'ResNeXt101':\n",
    "        cnn_model=resnext.ResNeXt101(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet',\n",
    "                                                  backend = keras.backend, layers = keras.layers, models = keras.models, utils = keras.utils)\n",
    "    if model == 'NetVGG19':\n",
    "        cnn_model=keras.applications.vgg19.VGG19(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet')\n",
    "    if model == 'VGG16':\n",
    "        cnn_model=keras.applications.vgg16.VGG16(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet')\n",
    "\n",
    "    if model == 'NetDenseNet121':\n",
    "        cnn_model=keras.applications.densenet.DenseNet121(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet')\n",
    "    \n",
    "    if model == 'NetDenseNet169':\n",
    "        cnn_model=keras.applications.densenet.DenseNet169(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet')\n",
    "   \n",
    "    if model == 'NetDenseNet201':\n",
    "        cnn_model=keras.applications.densenet.DenseNet201(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet')\n",
    "    \n",
    "    if model == 'NetNASNetLarge':\n",
    "        cnn_model=keras.applications.nasnet.NASNetLarge(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet')\n",
    "    \n",
    "    if model == 'NetNASNetMobile':\n",
    "        cnn_model=keras.applications.nasnet.NASNetMobile(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet')\n",
    "    \n",
    "    if model == 'NetMobileNet':\n",
    "        cnn_model=keras.applications.mobilenet.MobileNet(alpha=1.0, depth_multiplier=1, dropout=1e-3, include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet')  \n",
    "    \n",
    "    if model == 'InceptionResNetV2':\n",
    "        cnn_model=keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet')\n",
    "    \n",
    "    if model == 'NetDenseNet201':\n",
    "        cnn_model=keras.applications.densenet.DenseNet201(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet')          \n",
    "    \n",
    "    else:\n",
    "        cnn_model = InceptionV3(include_top=False, input_shape=(im_size, im_size, 3), weights='imagenet')\n",
    "    \n",
    "    for layer in cnn_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    inputs = Input((im_size, im_size, 3))\n",
    "    x = inputs\n",
    "    x = Lambda(preprocess_input, name='preprocessing')(x)\n",
    "    x = cnn_model(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    cnn_model = Model(inputs, x)\n",
    "    cnn_model.summary()\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Features at the bottom of the pre-trained models\n",
    "def bottleneck_features1(model='xception'):\n",
    "    xception_m = cnn_load_model(model)\n",
    "    features = xception_m.predict(x=X_train, batch_size=32, verbose=1)\n",
    "    np.save('data/saved_npy/'+model+'_featuretraining.npy',features)\n",
    "    return features\n",
    "features7 = np.asarray(bottleneck_features1(model='xception'))\n",
    "np.shape(features7)\n",
    "print(np.shape(features7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used softmax classifier for pre-trained features extracted from pre-trained models\n",
    "num_class = 3\n",
    "inputs = Input(features7.shape[1:])\n",
    "x = inputs\n",
    "x = Dense(256,activation = None)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dense(num_class, activation='softmax')(x)\n",
    "model = Model(inputs, x)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(features7, y_train, batch_size=64,validation_split = 0.20, epochs=100,verbose=1)\n",
    "#history = model.fit(X_train, Y_train, validation_split=0.20, epochs=20)\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bottleneck_features11(model='xception'):\n",
    "    xception_m = cnn_load_model(model)\n",
    "    featurestest = xception_m.predict(x=X_test, batch_size=32, verbose=1)\n",
    "    np.save('data/saved_npy/'+model+'_testfeatures.npy',featurestest)\n",
    "    return featurestest\n",
    "featurestest1 = np.asarray(bottleneck_features11(model='xception'))\n",
    "np.shape(featurestest1)\n",
    "## evaluate test accuracy\n",
    "score = model.evaluate(featurestest1, y_test, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test accuracy: %.4f%%' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can used these features extracted from pre-trained models in any machine learning classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingfeatures=features7\n",
    "testing features=featurestest1\n",
    "traininglabel=Y_train\n",
    "testinglabels=Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feed the extracted features with the labels to RANDOM FOREST \n",
    "rf = RandomForestClassifier(n_estimators = 20, random_state = 42,max_features=4)\n",
    "\n",
    "rf.fit(train_features, train_label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
